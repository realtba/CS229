{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn import svm\n",
    "from __future__ import division\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to read in the sparsematrix format used by CS229\n",
    "def readMatrix(filenname):\n",
    "    \n",
    "    file_matrix = open(filenname, \"r\")\n",
    "    lines = file_matrix.readlines()\n",
    "    \n",
    "    rowscols = (int(lines[1].split()[0]), int(lines[1].split()[1]))\n",
    "    tokenlist = lines[2]\n",
    "    matrix = lil_matrix((rowscols[1],rowscols[0]), dtype=np.int8)\n",
    "    category = np.zeros(rowscols[0])\n",
    "    line = np.zeros(rowscols[1])\n",
    "    \n",
    "    for i in range(rowscols[0]):\n",
    "        line = [int(lines[3+i].split()[j]) for j in range(len(lines[3+i].split()))]\n",
    "        category[i]=int(line[0])\n",
    "        cumsum = np.cumsum(line[1::2])\n",
    "        for j in range(len(line[1::2])-1):\n",
    "            matrix[cumsum[j],i] = line[2::2][j]\n",
    "    matrix.tocsc();\n",
    "    matrix = matrix.transpose()\n",
    "        \n",
    "    return (tokenlist, category, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trains the Naive Bayes algorithm given a category vector and a desgin matrix.\n",
    "# Returns the conditional probabilities logSpamPhi, logNoSpamPhi and the prioris logSpamPrior, logNoSpamPrior\n",
    "# The explicit form of these probabilities can be deduced by maximizing the joint log likelihood of the problem. \n",
    "def trainNaiveBayes(category, matrix):\n",
    "    \n",
    "    train = matrix.toarray()\n",
    "    documents = train.shape[0]\n",
    "    words = train.shape[1]\n",
    "    \n",
    "    spamTrain = np.array( [ train[i][:]  for i in range(documents) if category[i] == 1 ])\n",
    "    noSpamTrain = np.array([train[i][:] for i in range(documents) if category[i] == 0 ])\n",
    "    spamDocuments = spamTrain.shape[0]\n",
    "    noSpamDocuments = noSpamTrain.shape[0]\n",
    "    \n",
    "    logSpamPrior = np.log(spamDocuments / documents)\n",
    "    logNoSpamPrior = np.log(noSpamDocuments / documents)\n",
    "    allSpamWords = sum([sum([spamTrain[l][k] for l in range(spamDocuments)]) for k in range(words)])\n",
    "    allNoSpamWords = sum([sum([noSpamTrain[l][k] for l in range(noSpamDocuments)]) for k in range(words)])  \n",
    "    \n",
    "    logSpamPhi = np.log([( 1 + sum([spamTrain[i][j] for i in range(spamDocuments)])) /(words +allSpamWords)\n",
    "                  for j in range(words)])\n",
    "    \n",
    "    logNoSpamPhi = np.log([ (1 + sum([noSpamTrain[i][j] for i in range(noSpamDocuments)])) / (words + allNoSpamWords)\n",
    "                    for j in range(words)])\n",
    "    \n",
    "    return (logSpamPrior, logNoSpamPrior, logSpamPhi, logNoSpamPhi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uses Bayes' theorem to predict the class labels from the conditional probabilities logSpamPhi, logNoSpamPhi\n",
    "# and the prioris logSpamPrior, logNoSpamPrior\n",
    "\n",
    "def isSpam(mail, logSpamPrior, logNoSpamPrior, logSpamPhi, logNoSpamPhi):\n",
    "    \n",
    "    logPosterioriProbSpam = sum([mail[j]*logSpamPhi[j] for j in range(mail.shape[0])]) + logSpamPrior\n",
    "    logPosterioriProbNoSpam = sum([mail[j]*logNoSpamPhi[j] for j in range(mail.shape[0])]) + logNoSpamPrior\n",
    "    \n",
    "    return int(logPosterioriProbSpam > logPosterioriProbNoSpam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort the tokens in order of how indicative there are for spam\n",
    "def sortTokens(tokens, logSpamPrior, logNoSpamPrior, logSpamPhi, logNoSpamPhi):\n",
    "    sortedTokens = sorted(tokens.split(), key =lambda(token): np.log( ( logSpamPhi[tokens.split().index(token)] + logSpamPrior) \n",
    "                                                             /(logNoSpamPhi[tokens.split().index(token)] + logNoSpamPrior)))\n",
    "    \n",
    "    return sortedTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainSVM(category, matrix):\n",
    "    svmCategory = [2*category[i]-1 for i in range(len(category))]\n",
    "    classifier = svm.LinearSVC()\n",
    "    classifier.fit(matrix,svmCategory)\n",
    "    \n",
    "    return classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally print the errors. \n",
    "def printSolution():\n",
    "    \n",
    "    trainMatrix = [\"MATRIX.TRAIN.50\",\"MATRIX.TRAIN.100\", \"MATRIX.TRAIN.200\", \"MATRIX.TRAIN.400\",\n",
    "                   \"MATRIX.TRAIN.800\", \"MATRIX.TRAIN.1400\",\"MATRIX.TRAIN\"]\n",
    "    (testlist, categoryTest, test) = readMatrix(\"MATRIX.TEST\")\n",
    "    testArray = test.toarray()\n",
    "    \n",
    "    for matrix in trainMatrix:\n",
    "        \n",
    "        (tokenlist, category, trainMatrix) = readMatrix(matrix)\n",
    "        (logSpamPrior, logNoSpamPrior, logSpamPhi, logNoSpamPhi)= trainNaiveBayes(category, trainMatrix)\n",
    "        classifer = trainSVM(category, trainMatrix)\n",
    "        correct = sum([1 for i in range(testArray.shape[0]) \n",
    "                if (isSpam(testArray[i][:], logSpamPrior, logNoSpamPrior, logSpamPhi, logNoSpamPhi) == (categoryTest[i]==1))])/ testArray.shape[0]\n",
    "        correctSVM = sum([1 for i in range(testArray.shape[0]) \n",
    "            if ( (classifer.predict(testArray[i][:].reshape(1,-1))==1) == (categoryTest[i]==1))])/ testArray.shape[0]\n",
    "        \n",
    "        print  \"The error using Naive Bayes and the training sample \" + matrix + \" is: \" + str((1-correct)*100) +\"%.\"\n",
    "        print  \"The error using an SVM with a linear kernel and the training sample \" + matrix + \" is: \" + str((1-correctSVM)*100) +\"%.\"\n",
    "\n",
    "    sortedTokens = sortTokens(tokenlist,logSpamPrior, logNoSpamPrior, logSpamPhi, logNoSpamPhi)\n",
    "    print \"The five most indicative tokens for spam are:\"\n",
    "    for i in range(5):\n",
    "        print sortedTokens[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error using Naive Bayes and the training sample MATRIX.TRAIN.50 is: 3.5%.\n",
      "The error using an SVM with a linear kernel and the training sample MATRIX.TRAIN.50 is: 4.625%.\n",
      "The error using Naive Bayes and the training sample MATRIX.TRAIN.100 is: 2.25%.\n",
      "The error using an SVM with a linear kernel and the training sample MATRIX.TRAIN.100 is: 2.5%.\n",
      "The error using Naive Bayes and the training sample MATRIX.TRAIN.200 is: 2.25%.\n",
      "The error using an SVM with a linear kernel and the training sample MATRIX.TRAIN.200 is: 1.125%.\n",
      "The error using Naive Bayes and the training sample MATRIX.TRAIN.400 is: 1.625%.\n",
      "The error using an SVM with a linear kernel and the training sample MATRIX.TRAIN.400 is: 1.0%.\n",
      "The error using Naive Bayes and the training sample MATRIX.TRAIN.800 is: 1.75%.\n",
      "The error using an SVM with a linear kernel and the training sample MATRIX.TRAIN.800 is: 1.0%.\n",
      "The error using Naive Bayes and the training sample MATRIX.TRAIN.1400 is: 1.625%.\n",
      "The error using an SVM with a linear kernel and the training sample MATRIX.TRAIN.1400 is: 0.875%.\n",
      "The error using Naive Bayes and the training sample MATRIX.TRAIN is: 1.625%.\n",
      "The error using an SVM with a linear kernel and the training sample MATRIX.TRAIN is: 0.375%.\n",
      "The five most indicative tokens for spam are:\n",
      "httpaddr\n",
      "spam\n",
      "click\n",
      "unsubscrib\n",
      "ebai\n"
     ]
    }
   ],
   "source": [
    "printSolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
